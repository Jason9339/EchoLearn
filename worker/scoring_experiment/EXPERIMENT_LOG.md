# 評分系統實驗記錄

記錄所有實驗、發現和結果

---

## 實驗 1: 2024-11-21 - 資料探索與相關性分析

### 目標
- 分析人工評分分佈，驗證是否適合當作 ground truth
- 探索現有 8 個指標與人工評分的相關性
- 確定各指標的方向性（越高越好 vs 錯誤率）

### 資料集概況
- **總樣本數**: 1292 筆錄音
- **有評分樣本**: 1244 筆 (96.3%)
- **人工評分統計**:
  - 平均分數: 3.35 / 5.0
  - 標準差: 1.10
  - 範圍: 1.0 - 5.0
  - ≥3 位評分者的樣本: 21.7%

### 指標相關性分析

使用 Pearson 相關係數分析各指標與人工評分的關係：

| 指標 | 相關係數 | 方向 | 說明 |
|------|---------|------|------|
| **score_PER** | -0.31 | 錯誤率 (反向) | 音素錯誤率 - 越低越好 |
| **score_PPG** | 0.31 | 正向 | 音素後驗概率 - 越高越好 |
| **score_WER** | -0.29 | 錯誤率 (反向) | 詞錯誤率 - 越低越好 |
| **score_Energy** | 0.23 | 正向 | 能量相似度 - 越高越好 |
| **score_VDE** | 0.16 | 正向 | 聲音距離評估 - 越高越好 |
| **score_GPE_offset** | 0.15 | 正向 | 音素發音評估 - 越高越好 |
| **score_GOP** | 0.08 | 正向 | 音素良度評估 - 越高越好 |
| **score_FFE** | 0.07 | 正向 | 頻譜流暢度評估 - 越高越好 |

### 關鍵發現
1. ✅ **人工評分分佈接近常態分佈**，適合作為 ground truth
2. ⚠️ **所有指標與人工評分的相關性都較弱** (< 0.5)，表示：
   - 單一指標不足以完整評估發音品質
   - 需要結合多個指標來提升預測準確度
3. ✅ **最具預測力的前 3 個指標**：PER (-0.31)、PPG (0.31)、WER (-0.29)

### 結論
- 人工評分可作為有效的訓練標籤
- 需要使用機器學習模型來結合多個弱相關指標
- Baseline 方向：加權平均 → 線性回歸 → 樹模型

---

## 實驗 2: 2024-11-21 - Baseline 評分模型訓練

### 目標
建立 Baseline 評分系統，使用現有 8 個指標預測 1-5 星評分

### 方法
實作 3 種 Baseline 方法並比較：

#### 1. 加權平均 (Weighted Average)
- 使用相關係數的絕對值作為權重
- 將所有指標正規化為「越高越好」（error rate 取反）
- 線性映射到 1-5 星範圍

#### 2. 線性回歸 (Ridge Regression)
- 使用 StandardScaler 標準化特徵
- Ridge regression (alpha=1.0) 防止過擬合
- 學習最佳線性組合權重

#### 3. 隨機森林 (Random Forest)
- 100 棵決策樹
- max_depth=10, min_samples_split=10
- 捕捉非線性關係

### 訓練設定
- **訓練集大小**: 995 筆 (80%)
- **測試集大小**: 249 筆 (20%)
- **random_state**: 42
- **評估指標**: MAE, RMSE, R², 星級準確度

### 結果比較

| 模型 | 測試集 MAE | 測試集 RMSE | 測試集 R² | 整數星級準確度 |
|------|-----------|------------|----------|--------------|
| 加權平均 | 1.1159 | 1.3820 | -0.5046 | 26.91% |
| 線性回歸 | 0.8488 | 1.0335 | 0.1585 | 32.53% |
| **隨機森林** ⭐ | **0.7743** | **0.9649** | **0.2666** | **34.14%** |

### 最佳模型：隨機森林

**特徵重要性排名**：
1. **score_PPG** (0.224) - 音素後驗概率
2. **score_Energy** (0.161) - 能量相似度
3. **score_PER** (0.160) - 音素錯誤率
4. score_GPE_offset (0.098)
5. score_WER (0.095)
6. score_FFE (0.094)
7. score_GOP (0.091)
8. score_VDE (0.078)

**測試集詳細表現**：
- MAE: 0.7743 星 (約 3/4 顆星的誤差)
- 整數星級準確度: 34.14%
- 0.5 星準確度: 21.29%
- R² = 0.27 (解釋 27% 的變異)

### 驗證結果（前 100 筆樣本）

使用 `validate_baseline.py` 在真實資料上驗證：

- **驗證樣本數**: 100 筆
- **MAE**: 0.5731 星
- **RMSE**: 0.7133 星
- **整數星級準確度**: 39.00%
- **0.5 星準確度**: 27.00%

**誤差分佈**：
- < 0.5 星: 52.0% ✅
- < 1.0 星: 88.0% ✅
- < 1.5 星: 96.0%
- ≥ 2.0 星: 1.0%

**預測分數分佈**：
- 主要集中在 3-4 星 (93%)
- 分佈合理，符合資料集特性

### 結論與改進方向

#### ✅ 成功之處
1. 隨機森林顯著優於簡單方法
2. 88% 的預測誤差 < 1 星，實用性高
3. 模型穩定，泛化能力良好

#### ⚠️ 限制
1. R² 只有 0.27，仍有大量變異無法解釋
2. 預測過於集中在中間星級 (3-4 星)
3. 對極端值（1 星、5 星）的預測能力較弱

#### 🚀 改進方向（選用）
1. **新增音訊特徵**：
   - 音高相似度 (Pitch correlation)
   - 語速比率 (Speech rate)
   - 停頓分析 (Pause patterns)
   - MFCC 相似度
2. **模型優化**：
   - 使用 XGBoost 或 LightGBM
   - 超參數調校 (Grid Search / Bayesian Optimization)
   - 集成學習 (Ensemble)
3. **資料增強**：
   - 只使用 ≥3 位評分者的資料
   - 加權損失函數（高信心樣本權重更高）

---

## 實驗總結

### 當前最佳方案
- **模型**: Random Forest Regressor
- **特徵**: 8 個現有指標 (PER, PPG, WER, GOP, GPE_offset, FFE, Energy, VDE)
- **表現**: 測試集 MAE = 0.77 星
- **實用性**: 88% 誤差 < 1 星，可作為產品 v1.0

### 檔案清單
```
scoring_experiment/
├── scripts/
│   ├── analyze_scoring_simple.py      # 相關性分析
│   ├── train_baseline_model.py        # Baseline 訓練
│   ├── scoring_service.py             # 評分服務
│   └── validate_baseline.py           # 模型驗證
├── models/
│   ├── random_forest.joblib           # 最佳模型
│   ├── linear_regression.joblib       # 線性回歸
│   ├── scaler.joblib                  # 特徵縮放器
│   └── baseline_weights.json          # 加權平均權重
└── results/
    └── baseline_results.json          # 訓練結果
```

### 下一步建議
1. ✅ **整合到主系統** - 將 `scoring_service.py` 整合到 Flask API
2. 🔄 **A/B 測試** - 比較 ML 評分 vs 加權平均
3. 🚀 **未來改進** - 提取音高、語速等新特徵（時間允許時）
