#!/usr/bin/env python3
"""
å®Œæ•´çš„èªéŸ³è©•ä¼°æ¸¬è©¦ - æ•´åˆæ‰€æœ‰æŒ‡æ¨™
åŒ…å«ï¼š
1. ç”¨æˆ¶éŒ„éŸ³è©•ä¼°ï¼ˆèˆ‡åƒè€ƒéŸ³æª”æ¯”è¼ƒï¼‰
2. å››ç¨®æ¸¬è©¦æ¡ˆä¾‹ï¼ˆåŒæª”ã€ä¸åŒèªªè©±è€…ã€ä¸åŒå¥å­ç­‰ï¼‰
3. 11 é …å®Œæ•´æŒ‡æ¨™ï¼šéŸ³ç´ ç›¸ä¼¼åº¦ (5é …) + èªéŸ³éŸ»å¾‹ (6é …)
"""

import sys
import argparse
from pathlib import Path

# ç¢ºä¿å¯ä»¥ import services
sys.path.insert(0, str(Path(__file__).parent / "src"))

from services.phoneme_ctc import PhoneCTC
from services.phoneme_per import calculate_per_similarity
from services.phoneme_gop import calculate_gop_similarity
from services.phoneme_ppg import calculate_ppg_similarity
from services.preprocessing import preprocess_pipeline
from services.cal_wer_gop import get_wer_score, get_gop_score
from services.speech_metrics import SpeechMetrics


def test_user_recordings(use_deepfilter: bool, ctc: PhoneCTC, speech_metrics: SpeechMetrics):
    """æ¸¬è©¦ç”¨æˆ¶éŒ„éŸ³èˆ‡åƒè€ƒéŸ³æª”çš„æ¯”è¼ƒ"""
    print("\n" + "=" * 90)
    print("Part 1: ç”¨æˆ¶éŒ„éŸ³è©•ä¼°")
    print("=" * 90)

    # æª”æ¡ˆè·¯å¾‘
    recording_1 = Path("/home/vipl/EchoLearn/example_audio/a2736ebe-448c-450b-a5cc-370d680abd03_1_test-0_1762443387953.webm")
    recording_2 = Path("/home/vipl/EchoLearn/example_audio/a2736ebe-448c-450b-a5cc-370d680abd03_1_test-1_1762443401800.webm")
    recording_3 = Path("/home/vipl/EchoLearn/example_audio/6935f0d5-1298-4223-885e-6d204f112343_1_test-0_1761173329238.webm")
    reference = Path("/home/vipl/EchoLearn/public/audio/cmu_us_bdl_arctic/arctic_a0001.wav")

    output_dir = Path("/home/vipl/EchoLearn/example_audio")
    recording_1_processed = output_dir / "recording_1_processed.wav"
    recording_2_processed = output_dir / "recording_2_processed.wav"
    recording_3_processed = output_dir / "recording_3_processed.wav"
    reference_processed = output_dir / "reference_processed.wav"

    # æ”¶é›†å­˜åœ¨çš„éŒ„éŸ³
    recordings = []
    if recording_1.exists():
        recordings.append(("éŒ„éŸ³ 1", recording_1, recording_1_processed))
    if recording_2.exists():
        recordings.append(("éŒ„éŸ³ 2", recording_2, recording_2_processed))
    if recording_3.exists():
        recordings.append(("éŒ„éŸ³ 3", recording_3, recording_3_processed))

    if not recordings:
        print(f"âŒ æ‰¾ä¸åˆ°ä»»ä½•éŒ„éŸ³æª”æ¡ˆ")
        return []

    if not reference.exists():
        print(f"âŒ æ‰¾ä¸åˆ°åƒè€ƒéŸ³æª”: {reference}")
        return []

    print(f"\nâœ… æ‰¾åˆ° {len(recordings)} å€‹éŒ„éŸ³æª”æ¡ˆ")
    for name, path, _ in recordings:
        print(f"   {name}: {path.name}")
    print(f"   åƒè€ƒéŸ³æª”: {reference.name}")

    # è™•ç†éŸ³æª”
    print(f"\n{'=' * 90}")
    print("è™•ç†éŸ³æª”ï¼ˆæ ¼å¼è½‰æ› + æ¨™æº–åŒ–ï¼‰")
    print('=' * 90)

    for name, src_path, dst_path in recordings:
        print(f"è™•ç†{name}...")
        preprocess_pipeline(src_path, dst_path, use_deepfilter=use_deepfilter)
        print(f"âœ… å®Œæˆ: {dst_path.name}")

    print("\nè™•ç†åƒè€ƒéŸ³æª”...")
    preprocess_pipeline(reference, reference_processed, use_deepfilter=use_deepfilter)
    print(f"âœ… å®Œæˆ: {reference_processed.name}")

    # è¨ˆç®—æ‰€æœ‰æŒ‡æ¨™
    print(f"\n{'=' * 90}")
    print("è¨ˆç®—æ‰€æœ‰ç›¸ä¼¼åº¦æŒ‡æ¨™")
    print('=' * 90)

    all_results = []

    for i, (name, _, processed_path) in enumerate(recordings, 1):
        print(f"\n{'-' * 90}")
        print(f"æ¸¬è©¦ {i}: {name} vs åƒè€ƒéŸ³æª”")
        print('-' * 90)

        # éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™
        print("\nã€éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™ã€‘")
        per = calculate_per_similarity(str(processed_path), str(reference_processed), ctc=ctc)
        gop_new = calculate_gop_similarity(str(processed_path), str(reference_processed), ctc=ctc)
        ppg = calculate_ppg_similarity(str(processed_path), str(reference_processed), ctc=ctc)
        wer = get_wer_score(str(processed_path), str(reference_processed))
        gop_old = get_gop_score(str(processed_path), str(reference_processed), alignment=True)

        print(f"  PER: {per:.4f}, GOP-new: {gop_new:.4f}, PPG: {ppg:.4f}")
        print(f"  WER: {wer:.4f}, GOP-old: {gop_old:.4f}")

        # èªéŸ³éŸ»å¾‹æŒ‡æ¨™
        print("\nã€èªéŸ³éŸ»å¾‹æŒ‡æ¨™ã€‘")
        vde = speech_metrics.calculate_vde(str(reference_processed), str(processed_path))
        gpe = speech_metrics.calculate_gpe(str(reference_processed), str(processed_path))
        gpe_log = speech_metrics.calculate_gpe_log(str(reference_processed), str(processed_path))
        gpe_offset = speech_metrics.calculate_gpe_offset(str(reference_processed), str(processed_path))
        energy = speech_metrics.calculate_energy_similarity(str(reference_processed), str(processed_path))
        ffe = speech_metrics.calculate_ffe(str(reference_processed), str(processed_path))

        print(f"  VDE: {vde:.4f}, GPE: {gpe:.4f}, GPE_log: {gpe_log:.4f}")
        print(f"  GPE_offset: {gpe_offset:.4f}, Energy: {energy:.4f}, FFE: {ffe:.4f}")

        all_results.append({
            'name': name,
            'per': per, 'gop_new': gop_new, 'ppg': ppg, 'wer': wer, 'gop_old': gop_old,
            'vde': vde, 'gpe': gpe, 'gpe_log': gpe_log, 'gpe_offset': gpe_offset,
            'energy': energy, 'ffe': ffe
        })

    return all_results


def test_four_cases(ctc: PhoneCTC, speech_metrics: SpeechMetrics):
    """æ¸¬è©¦å››ç¨®æ¨™æº–æ¡ˆä¾‹ï¼ˆè¨ˆç®—å…¨éƒ¨ 11 é …æŒ‡æ¨™ï¼‰"""
    print("\n" + "=" * 90)
    print("Part 2: å››ç¨®æ¨™æº–æ¸¬è©¦æ¡ˆä¾‹")
    print("=" * 90)

    # éŸ³æª”è·¯å¾‘
    AUDIO_DIR = Path(__file__).parent.parent / "public" / "audio"
    BDL_DIR = AUDIO_DIR / "cmu_us_bdl_arctic"  # èªªè©±è€… 1 (ç”·è²)
    CLB_DIR = AUDIO_DIR / "cmu_us_clb_arctic"  # èªªè©±è€… 2 (å¥³è²)

    # æª¢æŸ¥éŸ³æª”ç›®éŒ„
    if not BDL_DIR.exists() or not CLB_DIR.exists():
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³æª”ç›®éŒ„")
        print(f"   é æœŸè·¯å¾‘: {AUDIO_DIR}")
        return []

    # é¸æ“‡æ¸¬è©¦éŸ³æª”
    bdl_file1 = BDL_DIR / "arctic_a0001.wav"
    bdl_file2 = BDL_DIR / "arctic_a0002.wav"
    clb_file1 = CLB_DIR / "arctic_a0001.wav"
    clb_file2 = CLB_DIR / "arctic_a0002.wav"

    # æª¢æŸ¥æª”æ¡ˆå­˜åœ¨
    for f in [bdl_file1, bdl_file2, clb_file1, clb_file2]:
        if not f.exists():
            print(f"âŒ æ‰¾ä¸åˆ°éŸ³æª” {f}")
            return []

    print("\nâœ… æ¸¬è©¦éŸ³æª”æº–å‚™å®Œæˆ")
    print(f"   èªªè©±è€… 1 (ç”·è²): {bdl_file1.name}, {bdl_file2.name}")
    print(f"   èªªè©±è€… 2 (å¥³è²): {clb_file1.name}, {clb_file2.name}")

    # å®šç¾©å››ç¨®æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        {
            'name': 'æ¸¬è©¦ 1: åŒæª”å°è‡ªå·±',
            'description': 'é æœŸ: æ‰€æœ‰æŒ‡æ¨™éƒ½æ¥è¿‘ 1.0ï¼ˆå®Œå…¨ç›¸åŒï¼‰',
            'audio_a': bdl_file1,
            'audio_b': bdl_file1,
        },
        {
            'name': 'æ¸¬è©¦ 2: ä¸åŒèªªè©±è€…åŒå¥',
            'description': 'é æœŸ: PER/WER é«˜ï¼ˆå…§å®¹ç›¸åŒï¼‰ï¼ŒéŸ»å¾‹æŒ‡æ¨™ä¸­ç­‰ï¼ˆéŸ³è‰²ä¸åŒï¼‰',
            'audio_a': bdl_file1,  # ç”·è²
            'audio_b': clb_file1,  # å¥³è² (åŒä¸€å¥)
        },
        {
            'name': 'æ¸¬è©¦ 3: åŒèªªè©±è€…ä¸åŒå¥',
            'description': 'é æœŸ: PER/WER ä½ï¼ˆå…§å®¹ä¸åŒï¼‰ï¼ŒéŸ»å¾‹æŒ‡æ¨™é«˜ï¼ˆéŸ³è‰²ç›¸åŒï¼‰',
            'audio_a': bdl_file1,  # ç”·è²å¥å­1
            'audio_b': bdl_file2,  # ç”·è²å¥å­2
        },
        {
            'name': 'æ¸¬è©¦ 4: ä¸åŒèªªè©±è€…ä¸åŒå¥',
            'description': 'é æœŸ: æ‰€æœ‰åˆ†æ•¸éƒ½è¼ƒä½ï¼ˆå…§å®¹å’ŒéŸ³è‰²éƒ½ä¸åŒï¼‰',
            'audio_a': bdl_file1,  # ç”·è²å¥å­1
            'audio_b': clb_file2,  # å¥³è²å¥å­2
        },
    ]

    results = []

    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'-' * 90}")
        print(f"{test_case['name']}")
        print(f"{test_case['description']}")
        print(f"éŸ³æª” A: {test_case['audio_a'].name}")
        print(f"éŸ³æª” B: {test_case['audio_b'].name}")
        print('-' * 90)

        try:
            # === éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™ ===
            print("\nã€éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™ã€‘")
            per = calculate_per_similarity(str(test_case['audio_a']), str(test_case['audio_b']), ctc=ctc)
            gop_new = calculate_gop_similarity(str(test_case['audio_a']), str(test_case['audio_b']), ctc=ctc)
            ppg = calculate_ppg_similarity(str(test_case['audio_a']), str(test_case['audio_b']), ctc=ctc)
            wer = get_wer_score(str(test_case['audio_a']), str(test_case['audio_b']))
            gop_old = get_gop_score(str(test_case['audio_a']), str(test_case['audio_b']), alignment=True)

            print(f"  PER: {per:.4f}, GOP-new: {gop_new:.4f}, PPG: {ppg:.4f}")
            print(f"  WER: {wer:.4f}, GOP-old: {gop_old:.4f}")

            # === èªéŸ³éŸ»å¾‹æŒ‡æ¨™ ===
            print("\nã€èªéŸ³éŸ»å¾‹æŒ‡æ¨™ã€‘")
            vde = speech_metrics.calculate_vde(str(test_case['audio_a']), str(test_case['audio_b']))
            gpe = speech_metrics.calculate_gpe(str(test_case['audio_a']), str(test_case['audio_b']))
            gpe_log = speech_metrics.calculate_gpe_log(str(test_case['audio_a']), str(test_case['audio_b']))
            gpe_offset = speech_metrics.calculate_gpe_offset(str(test_case['audio_a']), str(test_case['audio_b']))
            energy = speech_metrics.calculate_energy_similarity(str(test_case['audio_a']), str(test_case['audio_b']))
            ffe = speech_metrics.calculate_ffe(str(test_case['audio_a']), str(test_case['audio_b']))

            print(f"  VDE: {vde:.4f}, GPE: {gpe:.4f}, GPE_log: {gpe_log:.4f}")
            print(f"  GPE_offset: {gpe_offset:.4f}, Energy: {energy:.4f}, FFE: {ffe:.4f}")

            results.append({
                'name': test_case['name'],
                'per': per, 'gop_new': gop_new, 'ppg': ppg, 'wer': wer, 'gop_old': gop_old,
                'vde': vde, 'gpe': gpe, 'gpe_log': gpe_log, 'gpe_offset': gpe_offset,
                'energy': energy, 'ffe': ffe
            })

        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

    return results


def print_user_recordings_summary(all_results):
    """é¡¯ç¤ºç”¨æˆ¶éŒ„éŸ³çš„ç¸½çµ"""
    if not all_results:
        return

    print(f"\n{'=' * 90}")
    print("ç”¨æˆ¶éŒ„éŸ³æ¸¬è©¦ç¸½çµ")
    print('=' * 90)

    # éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™
    print(f"\nã€éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™ã€‘")
    print(f"{'éŒ„éŸ³':<15} {'PER':<10} {'GOP-new':<10} {'PPG':<10} {'WER':<10} {'GOP-old':<10}")
    print('-' * 90)
    for result in all_results:
        print(f"{result['name']:<15} {result['per']:<10.4f} {result['gop_new']:<10.4f} {result['ppg']:<10.4f} {result['wer']:<10.4f} {result['gop_old']:<10.4f}")

    # èªéŸ³éŸ»å¾‹æŒ‡æ¨™
    print(f"\nã€èªéŸ³éŸ»å¾‹æŒ‡æ¨™ã€‘")
    print(f"{'éŒ„éŸ³':<15} {'VDE':<10} {'GPE':<10} {'GPE_log':<10} {'GPE_off':<10} {'Energy':<10} {'FFE':<10}")
    print('-' * 90)
    for result in all_results:
        print(f"{result['name']:<15} {result['vde']:<10.4f} {result['gpe']:<10.4f} {result['gpe_log']:<10.4f} {result['gpe_offset']:<10.4f} {result['energy']:<10.4f} {result['ffe']:<10.4f}")

    # æœ€ä½³éŒ„éŸ³åˆ†æ
    if len(all_results) > 1:
        print(f"\nã€æœ€ä½³éŒ„éŸ³ã€‘")

        best_per = max(all_results, key=lambda x: x['per'])
        best_ppg = max(all_results, key=lambda x: x['ppg'])
        best_gpe = max(all_results, key=lambda x: x['gpe'])
        best_ffe = max(all_results, key=lambda x: x['ffe'])

        print(f"  æœ€ä½³ PER (éŸ³ç´ æº–ç¢ºåº¦):     {best_per['name']:<15} ({best_per['per']:.4f})")
        print(f"  æœ€ä½³ PPG (éŸ³ç´ åˆ†å¸ƒ):       {best_ppg['name']:<15} ({best_ppg['ppg']:.4f})")
        print(f"  æœ€ä½³ GPE (éŸ³é«˜ç›¸ä¼¼):       {best_gpe['name']:<15} ({best_gpe['gpe']:.4f})")
        print(f"  æœ€ä½³ FFE (F0å¹€ç›¸ä¼¼):      {best_ffe['name']:<15} ({best_ffe['ffe']:.4f})")

        # ç¶œåˆè©•åˆ†
        print(f"\nã€ç¶œåˆè©•åˆ†ã€‘")
        for result in all_results:
            avg_score = (
                result['per'] + result['gop_new'] + result['ppg'] +
                (1.0 - result['wer']) + result['gop_old'] +
                result['vde'] + result['gpe'] + result['gpe_offset'] +
                result['energy'] + result['ffe']
            ) / 10.0
            result['avg_score'] = avg_score
            print(f"  {result['name']:<15} å¹³å‡åˆ†æ•¸: {avg_score:.4f}")

        best_overall = max(all_results, key=lambda x: x['avg_score'])
        print(f"\n  ğŸ† ç¶œåˆè¡¨ç¾æœ€ä½³: {best_overall['name']} (å¹³å‡åˆ†æ•¸: {best_overall['avg_score']:.4f})")


def print_four_cases_summary(results):
    """é¡¯ç¤ºå››ç¨®æ¸¬è©¦æ¡ˆä¾‹çš„ç¸½çµï¼ˆæ‰€æœ‰ 11 é …æŒ‡æ¨™ï¼‰"""
    if not results:
        return

    print(f"\n{'=' * 90}")
    print("å››ç¨®æ¸¬è©¦æ¡ˆä¾‹ç¸½çµ")
    print('=' * 90)

    # éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™
    print(f"\nã€éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™ã€‘")
    print(f"{'æ¸¬è©¦æ¡ˆä¾‹':<25} {'PER':<10} {'GOP-new':<10} {'PPG':<10} {'WER':<10} {'GOP-old':<10}")
    print('-' * 90)
    for result in results:
        name = result['name'].replace('æ¸¬è©¦ ', 'T')
        print(f"{name:<25} {result['per']:<10.4f} {result['gop_new']:<10.4f} {result['ppg']:<10.4f} {result['wer']:<10.4f} {result['gop_old']:<10.4f}")

    # èªéŸ³éŸ»å¾‹æŒ‡æ¨™
    print(f"\nã€èªéŸ³éŸ»å¾‹æŒ‡æ¨™ã€‘")
    print(f"{'æ¸¬è©¦æ¡ˆä¾‹':<25} {'VDE':<10} {'GPE':<10} {'GPE_log':<10} {'GPE_off':<10} {'Energy':<10} {'FFE':<10}")
    print('-' * 90)
    for result in results:
        name = result['name'].replace('æ¸¬è©¦ ', 'T')
        print(f"{name:<25} {result['vde']:<10.4f} {result['gpe']:<10.4f} {result['gpe_log']:<10.4f} {result['gpe_offset']:<10.4f} {result['energy']:<10.4f} {result['ffe']:<10.4f}")

    # ç¶œåˆè©•åˆ†
    print(f"\nã€ç¶œåˆè©•åˆ†ã€‘ï¼ˆå¹³å‡æ‰€æœ‰ã€Œè¶Šé«˜è¶Šå¥½ã€æŒ‡æ¨™ï¼‰")
    for result in results:
        avg_score = (
            result['per'] + result['gop_new'] + result['ppg'] +
            (1.0 - result['wer']) + result['gop_old'] +
            result['vde'] + result['gpe'] + result['gpe_offset'] +
            result['energy'] + result['ffe']
        ) / 10.0
        result['avg_score'] = avg_score
        name = result['name'].replace('æ¸¬è©¦ ', 'T')
        print(f"  {name:<25} å¹³å‡åˆ†æ•¸: {avg_score:.4f}")

    # é©—è­‰é‚è¼¯
    print(f"\nã€é©—è­‰çµæœã€‘")
    validations = []

    for result in results:
        per, gop_new, ppg = result['per'], result['gop_new'], result['ppg']
        vde, energy, ffe = result['vde'], result['energy'], result['ffe']

        # æ ¹æ“šä¸åŒæ¸¬è©¦æ¡ˆä¾‹é©—è­‰çµæœ
        if 'åŒæª”å°è‡ªå·±' in result['name']:
            # æ‰€æœ‰æŒ‡æ¨™éƒ½æ‡‰è©²æ¥è¿‘ 1.0
            passed = per > 0.95 and gop_new > 0.95 and ppg > 0.95 and vde > 0.95 and energy > 0.95 and ffe > 0.95
            status = 'âœ… é€šé' if passed else 'âš ï¸ è­¦å‘Š'
            validations.append((result['name'], status, f"æ‰€æœ‰æŒ‡æ¨™æ‡‰æ¥è¿‘ 1.0 (avg={result['avg_score']:.4f})"))
        elif 'ä¸åŒèªªè©±è€…åŒå¥' in result['name']:
            # PER æ‡‰è©²è¼ƒé«˜ï¼ˆå…§å®¹ç›¸åŒï¼‰
            passed = per > 0.6
            status = 'âœ… é€šé' if passed else 'âš ï¸ è­¦å‘Š'
            validations.append((result['name'], status, f"PER æ‡‰è¼ƒé«˜ ({per:.4f} {'>' if passed else '<'} 0.6)"))
        elif 'åŒèªªè©±è€…ä¸åŒå¥' in result['name']:
            # éŸ»å¾‹æŒ‡æ¨™æ‡‰è©²è¼ƒé«˜ï¼ˆéŸ³è‰²ç›¸åŒï¼‰
            passed = energy > 0.6 and vde > 0.6
            status = 'âœ… é€šé' if passed else 'âš ï¸ è­¦å‘Š'
            validations.append((result['name'], status, f"éŸ»å¾‹æŒ‡æ¨™æ‡‰è¼ƒé«˜ (Energy={energy:.4f}, VDE={vde:.4f})"))
        elif 'ä¸åŒèªªè©±è€…ä¸åŒå¥' in result['name']:
            # æ‰€æœ‰åˆ†æ•¸éƒ½ä½æ˜¯é æœŸçµæœ
            passed = True
            status = 'âœ… é€šé'
            validations.append((result['name'], status, f"é æœŸæ‰€æœ‰åˆ†æ•¸éƒ½è¼ƒä½ (avg={result['avg_score']:.4f})"))

    for name, status, description in validations:
        name_short = name.replace('æ¸¬è©¦ ', 'T')
        print(f"  {name_short:<25} {status:<10} {description}")


def main():
    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser(
        description='å®Œæ•´çš„èªéŸ³è©•ä¼°æ¸¬è©¦ - æ•´åˆæ‰€æœ‰æŒ‡æ¨™',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¯„ä¾‹:
  # ä¸ä½¿ç”¨é™å™ªï¼ˆé è¨­ï¼Œå¿«é€Ÿï¼‰
  python test_all_metrics.py

  # ä½¿ç”¨ DeepFilterNet é™å™ªï¼ˆè¼ƒæ…¢ä½†å“è³ªæ›´å¥½ï¼‰
  python test_all_metrics.py --denoise
  python test_all_metrics.py -d
        '''
    )
    parser.add_argument(
        '--denoise', '-d',
        action='store_true',
        help='å•Ÿç”¨ DeepFilterNet é™å™ªï¼ˆé©åˆæœ‰é›œè¨Šçš„éŒ„éŸ³ï¼‰'
    )
    args = parser.parse_args()

    use_deepfilter = args.denoise

    print("=" * 90)
    print("å®Œæ•´çš„èªéŸ³è©•ä¼°æ¸¬è©¦ - æ•´åˆæ‰€æœ‰æŒ‡æ¨™")
    print("=" * 90)
    print(f"é™å™ªæ¨¡å¼: {'âœ… å•Ÿç”¨ DeepFilterNet' if use_deepfilter else 'âŒ é—œé–‰ï¼ˆåƒ…æ¨™æº–åŒ–ï¼‰'}")
    print("=" * 90)
    print("\næœ¬æ¸¬è©¦åŒ…å«å…©å€‹éƒ¨åˆ†:")
    print("  Part 1: ç”¨æˆ¶éŒ„éŸ³è©•ä¼° (11 é …å®Œæ•´æŒ‡æ¨™)")
    print("  Part 2: å››ç¨®æ¨™æº–æ¸¬è©¦æ¡ˆä¾‹ (11 é …å®Œæ•´æŒ‡æ¨™)")
    print("=" * 90)

    # è¼‰å…¥æ¨¡å‹
    print(f"\n{'=' * 90}")
    print("è¼‰å…¥æ¨¡å‹")
    print('=' * 90)

    print("è¼‰å…¥ PhoneCTC æ¨¡å‹...")
    ctc = PhoneCTC()
    print("âœ… PhoneCTC æ¨¡å‹è¼‰å…¥æˆåŠŸ")

    print("\nåˆå§‹åŒ– SpeechMetrics...")
    speech_metrics = SpeechMetrics(frame_shift=0.010)
    print("âœ… SpeechMetrics åˆå§‹åŒ–å®Œæˆ")

    # Part 1: æ¸¬è©¦ç”¨æˆ¶éŒ„éŸ³
    user_results = test_user_recordings(use_deepfilter, ctc, speech_metrics)

    # Part 2: æ¸¬è©¦å››ç¨®æ¨™æº–æ¡ˆä¾‹
    four_cases_results = test_four_cases(ctc, speech_metrics)

    # é¡¯ç¤ºç¸½çµ
    print_user_recordings_summary(user_results)
    print_four_cases_summary(four_cases_results)

    # æŒ‡æ¨™èªªæ˜
    print(f"\n{'=' * 90}")
    print("æŒ‡æ¨™èªªæ˜")
    print('=' * 90)

    print("\nã€éŸ³ç´ ç›¸ä¼¼åº¦æŒ‡æ¨™ã€‘(åŸºæ–¼ PhoneCTC æ¨¡å‹)")
    print("  PER (Phoneme Error Rate Similarity):        éŸ³ç´ åºåˆ—åŒ¹é…ï¼Œ1.0=å®Œå…¨ç›¸åŒ")
    print("  GOP-new (Goodness of Pronunciation):        ç™¼éŸ³å“è³ªï¼Œ1.0=å“è³ªå®Œå…¨ç›¸åŒ")
    print("  PPG (Posteriorgram Similarity):             éŸ³ç´ å¾Œé©—åœ–ï¼Œ1.0=åˆ†å¸ƒå®Œå…¨ç›¸åŒ")

    print("\nã€èˆŠç‰ˆæŒ‡æ¨™ã€‘")
    print("  WER (Word Error Rate):                      è©éŒ¯èª¤ç‡(Whisper)ï¼Œ0.0=å®Œå…¨ç›¸åŒ(è¶Šä½è¶Šå¥½)")
    print("  GOP-old (Goodness of Pronunciation):        ç™¼éŸ³å“è³ª(wav2vec2)ï¼Œ1.0=å“è³ªå®Œå…¨ç›¸åŒ")

    print("\nã€èªéŸ³éŸ»å¾‹æŒ‡æ¨™ã€‘(åŸºæ–¼ Praat è²å­¸åˆ†æ)")
    print("  VDE (Voiced Decision Error):                æ¿éŸ³åˆ¤æ–·ç›¸ä¼¼åº¦ï¼Œ1.0=å®Œå…¨ä¸€è‡´")
    print("  GPE (Gross Pitch Error):                    éŸ³é«˜ç›¸ä¼¼åº¦(æ¨™æº–)ï¼Œ1.0=ç„¡å¤§èª¤å·®")
    print("  GPE_log (GPE - Semitone):                   éŸ³é«˜ç›¸ä¼¼åº¦(åŠéŸ³)ï¼Œ1.0=åå·®éƒ½åœ¨3åŠéŸ³å…§")
    print("  GPE_offset (GPE - Pitch Contour):           éŸ³é«˜è¼ªå»“ç›¸ä¼¼åº¦(è£œå„Ÿæ•´é«”éŸ³é«˜)ï¼Œ1.0=è¼ªå»“ä¸€è‡´")
    print("  Energy (Energy Similarity):                 èƒ½é‡ç›¸ä¼¼åº¦ï¼Œ1.0=å®Œå…¨ç›¸åŒ")
    print("  FFE (F0 Frame Error):                       F0å¹€ç›¸ä¼¼åº¦ï¼Œ1.0=æ‰€æœ‰å¹€æ­£ç¢º")

    print(f"\n{'=' * 90}")
    print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
    print("   - Part 1: ç”¨æˆ¶éŒ„éŸ³è©•ä¼° (11 é …æŒ‡æ¨™)")
    print("   - Part 2: å››ç¨®æ¨™æº–æ¸¬è©¦æ¡ˆä¾‹ (11 é …æŒ‡æ¨™)")
    print("   - ç¸½è¨ˆ: 11 é …è©•ä¼°æŒ‡æ¨™ Ã— 2 ç¨®æ¸¬è©¦å ´æ™¯")
    print('=' * 90)


if __name__ == "__main__":
    main()
